<!doctype html><html lang=en><head><meta charset=utf-8><meta content=no-referrer name=referrer><meta content="width=device-width,initial-scale=1.0,maximum-scale=5" name=viewport><title>Graphics and System Readings | Jiacheng's Mini Blog</title><meta content="Graphics and System Readings | Jiacheng's Mini Blog" property=og:title><meta content="Graphics and System Readings | Jiacheng's Mini Blog" name=twitter:title><meta content="Blogs and news read during March 2021 that I found interesting." name=description><meta content="Blogs and news read during March 2021 that I found interesting." property=og:description><meta content="Blogs and news read during March 2021 that I found interesting." name=twitter:description><meta content="Jiacheng's Mini Blog" property=og:site_name><meta content=https://jason0214.github.io property=og:url><link crossorigin href=https://fonts.gstatic.com rel=preconnect><link href=https://jason0214.github.io/base.css rel=stylesheet><link href=https://fonts.googleapis.com rel=preconnect><link crossorigin href=https://fonts.gstatic.com rel=preconnect><link href="https://fonts.googleapis.com/css2?family=Atkinson+Hyperlegible:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel=stylesheet><link href=https://jason0214.github.io/fontawesome/fontawesome.css rel=stylesheet><link href=https://jason0214.github.io/fontawesome/brands.css rel=stylesheet><link href=https://jason0214.github.io/fontawesome/solid.css rel=stylesheet><link href=https://jason0214.github.io/favicon.ico rel=icon type=image/x-icon><body><a class="skip-link p-screen-reader-text" href=#main>Skip to content</a><header class=l-header><h1 class="c-title p-title"><a class=p-title__link href=https://jason0214.github.io>Jiacheng's Mini Blog</a></h1><p class=p-subtitle>Less tech, more life</header><main class=l-main id=main><article class=p-article><header><h1>Graphics and System Readings</h1><div><div class=c-time><time datetime=" 2021-03-07"> 2021-03-07 </time> - (10 min read)</div></div></header><section class=p-article__body id=js-article><p>Blogs and news read during March 2021 that I found interesting.</p><span id=continue-reading></span><p>Disclaimer: Opinions on my own and please judge the credibility by yourself.<p>[[toc]]<h3 id=proton-has-enabled-7000-windows-games-to-run-on-linux>Proton Has Enabled 7000 Windows Games To Run On Linux<a aria-label="Anchor link for: proton-has-enabled-7000-windows-games-to-run-on-linux" class=zola-anchor href=#proton-has-enabled-7000-windows-games-to-run-on-linux><i class="fas fa-link"></i></a></h3><p><a href=https://boilingsteam.com/7000-windows-games-working-on-linux-with-proton/>https://boilingsteam.com/7000-windows-games-working-on-linux-with-proton/</a> - March 05, 2021<blockquote><p>for every Windows game out there, there’s a coin flip chance that it will work just as well on Linux ... Note that when a game does not run well with vanilla Proton, there’s always a non-negligible chance that Proton GE may fare better at running it.</blockquote><h3 id=llvm-meets-code-property-graphs>LLVM meets Code Property Graphs<a aria-label="Anchor link for: llvm-meets-code-property-graphs" class=zola-anchor href=#llvm-meets-code-property-graphs><i class="fas fa-link"></i></a></h3><p><a href=https://blog.llvm.org/posts/2021-02-23-llvm-meets-code-property-graphs/>https://blog.llvm.org/posts/2021-02-23-llvm-meets-code-property-graphs/</a><blockquote><p>The code property graph (CPG) is a data structure designed to mine large codebases for instances of programming patterns via a domain-specific query language ... The core idea of the CPG is that different classic program representations are merged into a property graph, a single data structure that holds information about the program’s syntax, control- and intra-procedural data-flow ...</blockquote><blockquote><p>One of the primary interfaces to the code property graphs is a tool called Joern ... This article presents ShiftLeft‘s open-source implementation of llvm2cpg - a standalone tool that brings LLVM Bitcode support to Joern.</blockquote><blockquote><p>Joern comes with a data-flow tracker enabling more sophisticated queries, such as “is there a user controlled malloc in the program?”</blockquote><p>The data flow tracker that is able to check dynamic allocation in the program seems very interesting.<h3 id=new-vulkan-extensions-for-mobile-maintenance-extensions>New Vulkan Extensions For Mobile: Maintenance Extensions<a aria-label="Anchor link for: new-vulkan-extensions-for-mobile-maintenance-extensions" class=zola-anchor href=#new-vulkan-extensions-for-mobile-maintenance-extensions><i class="fas fa-link"></i></a></h3><p><a href=https://community.arm.com/developer/tools-software/graphics/b/blog/posts/vulkan-maintenance-extensions>https://community.arm.com/developer/tools-software/graphics/b/blog/posts/vulkan-maintenance-extensions</a><ul><li>VK_KHR_uniform_buffer_standard_layout: Some history of std140 and std430 UBO layout and how they are different in alignment. This extension brings std430 UBO layout to Vulkan.<li>VK_KHR_separate_depth_stencil_layouts: Depth and stencil are commonly being packed together. It leads to inconvenience in scenarios where depth buffer and stencil buffer are used in different pipeline stages. This extension supports an explicit decoupling of depth and stencil buffer.<li>VK_KHR_imageless_framebuffer: Extension supports creating VkFramebuffer without specifying attachments, delaying attachment binding to command recording time. It saves applications from keeping a mapping between framebuffers and attachments. In my understanding, now framebuffer and renderpass can be one-one mapped in most cases.</ul><h3 id=new-game-changing-vulkan-extensions-for-mobile-buffer-device-address>New Game Changing Vulkan Extensions For Mobile: Buffer Device Address<a aria-label="Anchor link for: new-game-changing-vulkan-extensions-for-mobile-buffer-device-address" class=zola-anchor href=#new-game-changing-vulkan-extensions-for-mobile-buffer-device-address><i class="fas fa-link"></i></a></h3><p><a href=https://community.arm.com/developer/tools-software/graphics/b/blog/posts/vulkan-buffer-device-address>https://community.arm.com/developer/tools-software/graphics/b/blog/posts/vulkan-buffer-device-address</a><blockquote><p>... none of the competing graphics APIs support. Extensions that support getting the GPU virtual address of a buffer. With the extension, it is possible for a shader to read/write a buffer without binding its descriptors. Though not sure if there is any practical case to do it that way. Maybe some debugging tools can utilize it? The extension also comes with a feature called <code>bufferDeviceAddressCaptureReplay</code>. Looks like using the extension could break capture replay tools. Not intuitive to me how it breaks, is that because applications may have different code paths for different returned virtual addresses?</blockquote><h3 id=new-game-changing-vulkan-extensions-for-mobile-descriptor-indexing>New Game Changing Vulkan Extensions For Mobile: Descriptor Indexing<a aria-label="Anchor link for: new-game-changing-vulkan-extensions-for-mobile-descriptor-indexing" class=zola-anchor href=#new-game-changing-vulkan-extensions-for-mobile-descriptor-indexing><i class="fas fa-link"></i></a></h3><p><a href=https://community.arm.com/developer/tools-software/graphics/b/blog/posts/vulkan-descriptor-indexing>https://community.arm.com/developer/tools-software/graphics/b/blog/posts/vulkan-descriptor-indexing</a><p>VK_EXT_descriptor_indexing brings update-after-bin support for descriptors. In my understanding, it is similar to the concept of a dynamic uniform buffer that you create a big chunk of memory but only use portions of it in each draw call. However, this extension does it to the descriptors of the uniform buffer, not the uniform buffer itself.<h3 id=moving-the-machinery-to-bindless>Moving The Machinery to Bindless<a aria-label="Anchor link for: moving-the-machinery-to-bindless" class=zola-anchor href=#moving-the-machinery-to-bindless><i class="fas fa-link"></i></a></h3><p><a href=https://ourmachinery.com/post/moving-the-machinery-to-bindless/>https://ourmachinery.com/post/moving-the-machinery-to-bindless/</a><p>Using VK_EXT_descriptor_indexing in practice. It creates a maxminal number of descriptor set bindings beforehand and then allocate and free descriptors dynamically in each command draw. It uses a linked list to track the free slots of descriptors in the big descriptor set bindings.<h3 id=opengl-on-directx-conformance-upstreaming-of-the-d3d12-driver>OpenGL on DirectX: Conformance & upstreaming of the D3D12 driver<a aria-label="Anchor link for: opengl-on-directx-conformance-upstreaming-of-the-d3d12-driver" class=zola-anchor href=#opengl-on-directx-conformance-upstreaming-of-the-d3d12-driver><i class="fas fa-link"></i></a></h3><p><a href=https://www.collabora.com/news-and-blog/news-and-events/opengl-directx-conformance-upstreaming-d3d12.html>https://www.collabora.com/news-and-blog/news-and-events/opengl-directx-conformance-upstreaming-d3d12.html</a><blockquote><p>... have recently passed the OpenGL 3.3 conformance tests,</blockquote><blockquote><p>... The D3D12 driver was upstreamed in Mesa in Merge-Request 7477, and the OpenCL compiler followed in Merge-Request 7565.</blockquote><blockquote><p>Next step, WSL support!</blockquote><h3 id=headless-native-backend-and-virtual-monitors>Headless Native Backend and Virtual Monitors<a aria-label="Anchor link for: headless-native-backend-and-virtual-monitors" class=zola-anchor href=#headless-native-backend-and-virtual-monitors><i class="fas fa-link"></i></a></h3><p><a href=https://gitlab.gnome.org/GNOME/mutter/-/merge_requests/1698>https://gitlab.gnome.org/GNOME/mutter/-/merge_requests/1698</a><blockquote><p>Ability to run the native backend on top of only a render node (i.e. no mode setting) and without evdev (a.k.a. "headless") Ability to create virtual monitors via command line arguments, primarily for debugging purposes Ability to create virtual monitors PipeWire streams via a new org.gnome.Mutter.ScreenCast.Session.RecordVirtual D-Bus method ... another way for the headless mode to run under: surfaceless EGL context. This should make it possible to run headlessly without a render node too.</blockquote><p>Mutter has merged a change to support running on render node only (through Wayland) as well as without render node through EGL surfaceless. Looks like now it is possible to recording gnome-shell from start to end very easily.<h3 id=apple-m1-microarchitecture-research>Apple M1 Microarchitecture Research<a aria-label="Anchor link for: apple-m1-microarchitecture-research" class=zola-anchor href=#apple-m1-microarchitecture-research><i class="fas fa-link"></i></a></h3><p><a href=https://dougallj.github.io/applecpu/firestorm.html>https://dougallj.github.io/applecpu/firestorm.html</a><blockquote><p>Certain instructions are able to issue as one uop if they appear consecutively in the instruction stream.</blockquote><p>Apple M1 has instruction fusion.<h3 id=full-wayland-setup-on-arch-linux>Full Wayland Setup on Arch Linux<a aria-label="Anchor link for: full-wayland-setup-on-arch-linux" class=zola-anchor href=#full-wayland-setup-on-arch-linux><i class="fas fa-link"></i></a></h3><p><a href=https://www.fosskers.ca/en/blog/wayland>https://www.fosskers.ca/en/blog/wayland</a><blockquote><p>The about:support page in Firefox has a field titled Window Protocol that tells us which protocol it is running through ... Set the MOZ_ENABLE_WAYLAND environment variable to 1.</blockquote><blockquote><p>Chromium's conversion is a bit simpler. In /home/you/.config/chromium-flags.conf, add the following lines: --enable-features=UseOzonePlatform --ozone-platform=wayland</blockquote><blockquote><p>Steam and Gaming ... set -x SDL_VIDEODRIVER 'wayland' ...</blockquote><p>Configurations for Firefox, Chromium and Steam games to run on top of native Wayland.<h3 id=makes-continuous-profiling-possible>Makes Continuous Profiling Possible<a aria-label="Anchor link for: makes-continuous-profiling-possible" class=zola-anchor href=#makes-continuous-profiling-possible><i class="fas fa-link"></i></a></h3><p><a href=https://github.com/pyroscope-io>https://github.com/pyroscope-io</a><p>Looks like a <code>perf top</code> for python and with a nice UI. Would be happy to try it out.<h3 id=what-are-some-10x-software-product-innovations-you-have-experienced>What Are Some “10x” Software Product Innovations You Have Experienced?<a aria-label="Anchor link for: what-are-some-10x-software-product-innovations-you-have-experienced" class=zola-anchor href=#what-are-some-10x-software-product-innovations-you-have-experienced><i class="fas fa-link"></i></a></h3><p><a href="https://news.ycombinator.com/item?id=26477507">https://news.ycombinator.com/item?id=26477507</a><p>Some examples mentioned are: sing Google for search in 2000, Google Maps in 2004, MS Window Media Player's, SQLite library, C++ STL in late 1990s, VMware in 2000s, Google Chrome in 2008, etc. All of them are before from decades or even before.<h3 id=match-differentiable-material-graphs-for-procedural-material-capture>MATch: Differentiable Material Graphs for Procedural Material Capture<a aria-label="Anchor link for: match-differentiable-material-graphs-for-procedural-material-capture" class=zola-anchor href=#match-differentiable-material-graphs-for-procedural-material-capture><i class="fas fa-link"></i></a></h3><p><a href=http://match.csail.mit.edu/>http://match.csail.mit.edu</a> <a href=https://users.cg.tuwien.ac.at/zsolnai/gfx/photorealistic-material-editing/>https://users.cg.tuwien.ac.at/zsolnai/gfx/photorealistic-material-editing/</a><blockquote><p>MATch, a method to automatically convert photographs of material samples into production-grade procedural material models a new library DiffMat that provides differentiable building blocks for constructing procedural materials, which can be used to automatically translate large-scale procedural models, with hundreds to thousands of node parameters, into differentiable node graphs.</blockquote><p>One of few applications of machine learning that really convinces me ML is the future. I have played with material editting using the Cycles Engine in Blender. I know how hard it is for a non-artist to use node graph to create realistic material. IMO, "MATch" is a revolutionary techique to this field. Get the node graph of texture in a photo is an end to end experience, with no requiring of knowledge on "node" or "material". Amazing! The limitation is that user still need to select a "base texture". Understandable, because noise patterns are not differentiable. And it does not hurt since choose a "noise node" is the easy part in the material creation pipeline.<h3 id=plan-9-from-bell-labs-in-cyberspace>Plan 9 from Bell Labs in Cyberspace!<a aria-label="Anchor link for: plan-9-from-bell-labs-in-cyberspace" class=zola-anchor href=#plan-9-from-bell-labs-in-cyberspace><i class="fas fa-link"></i></a></h3><p><a href=https://www.bell-labs.com/institute/blog/plan-9-bell-labs-cyberspace/>https://www.bell-labs.com/institute/blog/plan-9-bell-labs-cyberspace/</a><blockquote><p>what many don’t know is the team that created UNIX also developed another operating system in the 1980s ... The system in question is the Plan 9 OS from Bell Labs, ... This OS may not be as famous as UNIX, but it has been highly influential in its own ways, spearheading several concepts that are cornerstones of distributed computing systems today.</blockquote><blockquote><p>The OS is structured as a collection of loosely coupled services, which may be hosted on different machines. Another key concept in its design is that of a per-process name space: services can be mapped on to local names fixed by convention, so that programs using those services need not change if the current services are replaced by others providing the same functionality.</blockquote><p>sidebar: The Plan 9 file system protocol, a.k.a 9p, is used in popular softwares such as WSL, QEMU.<h3 id=expert-to-expert-rich-hickey-and-brian-beckman-inside-clojure>Expert to Expert: Rich Hickey and Brian Beckman - Inside Clojure<a aria-label="Anchor link for: expert-to-expert-rich-hickey-and-brian-beckman-inside-clojure" class=zola-anchor href=#expert-to-expert-rich-hickey-and-brian-beckman-inside-clojure><i class="fas fa-link"></i></a></h3><p><a href=https://channel9.msdn.com/Shows/Going+Deep/Expert-to-Expert-Rich-Hickey-and-Brian-Beckman-Inside-Clojure>https://channel9.msdn.com/Shows/Going+Deep/Expert-to-Expert-Rich-Hickey-and-Brian-Beckman-Inside-Clojure</a><p>Amazing talk. Especially the internal design part in the last half. Interestingly, the design of immutable data structures in Clojure (or maybe it is a general design for LISP) looks very similar to how git works. The git commit (variable) is a tree of snapshots (values) and make a new commit (create new value from the old) preserve the time complexity.<h3 id=auto-hdr-preview-for-pc-available-today>Auto HDR Preview for PC Available Today<a aria-label="Anchor link for: auto-hdr-preview-for-pc-available-today" class=zola-anchor href=#auto-hdr-preview-for-pc-available-today><i class="fas fa-link"></i></a></h3><p><a href=https://devblogs.microsoft.com/directx/auto-hdr-preview-for-pc-available-today/>https://devblogs.microsoft.com/directx/auto-hdr-preview-for-pc-available-today/</a><h3 id=how-to-reconstruct-an-image-if-you-see-only-a-few-pixels>How to reconstruct an image if you see only a few pixels<a aria-label="Anchor link for: how-to-reconstruct-an-image-if-you-see-only-a-few-pixels" class=zola-anchor href=#how-to-reconstruct-an-image-if-you-see-only-a-few-pixels><i class="fas fa-link"></i></a></h3><p><a href=https://towardsdatascience.com/how-to-reconstruct-an-image-if-you-see-only-a-few-pixels-e3899d038bf9#4218-42d96b4589ee>https://towardsdatascience.com/how-to-reconstruct-an-image-if-you-see-only-a-few-pixels-e3899d038bf9#4218-42d96b4589ee</a><blockquote><p>Image-space is vast, incredibly vast, and yet so small. Think about it for a second. You can create 18 446 744 073 709 551 616 different images by considering a grid as small as 8 by 8 black and white pixels. Yet, among these 18 quintillion images, very few make sense for human beings. Most images basically look like QR codes. Those making sense to human beings belongs to what we could call the set of natural images.</blockquote><p>Minimizing energy on pixel space and frequency space can recover the whole image when only 10% of its pixels is known.<h3 id=mesa-developers-discuss-the-possibility-of-rust-graphics-driver-code>Mesa Developers Discuss The Possibility Of Rust Graphics Driver Code<a aria-label="Anchor link for: mesa-developers-discuss-the-possibility-of-rust-graphics-driver-code" class=zola-anchor href=#mesa-developers-discuss-the-possibility-of-rust-graphics-driver-code><i class="fas fa-link"></i></a></h3><p><a href="https://www.phoronix.com/scan.php?page=news_item&px=AMD-Hiring-Radeon-Rust">https://www.phoronix.com/scan.php?page=news_item&px=AMD-Hiring-Radeon-Rust</a> <a href="https://www.phoronix.com/scan.php?page=news_item&px=Mesa-Rust-2020-Discussion">https://www.phoronix.com/scan.php?page=news_item&px=Mesa-Rust-2020-Discussion</a><p>Rust are being brought up in graphics community. It is Alyssa again.<h3 id=nvidia-proposes-mesa-patches-to-support-alternative-gbm-back-ends>NVIDIA Proposes Mesa Patches To Support Alternative GBM Back-Ends<a aria-label="Anchor link for: nvidia-proposes-mesa-patches-to-support-alternative-gbm-back-ends" class=zola-anchor href=#nvidia-proposes-mesa-patches-to-support-alternative-gbm-back-ends><i class="fas fa-link"></i></a></h3><p><a href="https://www.phoronix.com/scan.php?page=news_item&px=NVIDIA-GBM-Mesa-Backend-Alt">https://www.phoronix.com/scan.php?page=news_item&px=NVIDIA-GBM-Mesa-Backend-Alt</a> <a href=https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/9902>https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/9902</a><p>Finally Nvidia is turning to GBM. And it will be another backend insteand of DRI.</section><footer><nav class="c-pagination p-pagination"><div class=c-pagination__ctrl><div class=c-pagination__newer></div><div class=c-pagination__older></div></div></nav></footer></article></main><footer class=l-footer><p class=p-copyright></footer>